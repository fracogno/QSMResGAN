{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import nibabel as nib\n",
    "\n",
    "import UNET, Pix2Pix, utilities as util, datainputfn as inputfn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e8711e350be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"traintrain1-size64-ex512_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_forward_tfrange.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"traintrain1-size64-ex512_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_ground_truth_tfrange.nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nibabel/dataobj_images.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, caching)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \"\"\"\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    507\u001b[0m                              \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                              \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                              offset=offset)\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0;31m# The error raised by memmap, for different file types, has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# changed in different incarnations of the numpy routine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mbytes\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0marray_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         self = ndarray.__new__(subtype, shape, dtype=descr, buffer=mm,\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 24] Too many open files"
     ]
    }
   ],
   "source": [
    "path = \"/home/francesco/UQ/Job/QSM-GAN/data/shapes_shape64_ex512_2019_05_01/\"\n",
    "\n",
    "X, Y = [], []\n",
    "for i in range(1, 512):\n",
    "    X.append(nib.load(path + \"traintrain1-size64-ex512_\" + str(i) + \"_forward_tfrange.nii\").get_data())\n",
    "    Y.append(nib.load(path + \"traintrain1-size64-ex512_\" + str(i) + \"_ground_truth_tfrange.nii\").get_data())\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "Y = np.expand_dims(Y, axis=-1)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print(Y.max())\n",
    "print(Y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-5-7_1532_shapes_shape16_ex5_2019_03_26\n"
     ]
    }
   ],
   "source": [
    "last_path = \"shapes_shape16_ex5_2019_03_26\"\n",
    "path = \"/home/francesco/UQ/Job/deepQSM/data/\" + last_path\n",
    "\n",
    "currenttime = datetime.datetime.now()\n",
    "\n",
    "checkpointName = str(currenttime.year) + \"-\" + str(currenttime.month) + \"-\" + \\\n",
    "                    str(currenttime.day) + \"_\" + str(currenttime.hour) + str(currenttime.minute) + \\\n",
    "                    \"_\" + last_path\n",
    "print(checkpointName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = (16, 16, 16, 1)\n",
    "\n",
    "\n",
    "#train_data_filename = util.generate_file_list(file_path=path + \"/train/\", p_shape=input_shape)\n",
    "#eval_data_filename = util.generate_file_list(file_path=path + \"/train/\", p_shape=input_shape)\n",
    "\n",
    "#train_input_fn = inputfn.data_input_fn(train_data_filename, p_shape=input_shape,\n",
    "#                                       batch=1, nepochs=1, shuffle=True)\n",
    "\n",
    "#eval_input_fn = inputfn.data_input_fn(eval_data_filename, p_shape=input_shape, \n",
    "#                                      batch=5, nepochs=1, shuffle=False)\n",
    "\n",
    "# Unpack tensors\n",
    "#train_data = train_input_fn()\n",
    "#val_data = eval_input_fn()\n",
    "\n",
    "# Construct a suitable iterator (and ops) for switching between the datasets\n",
    "#iterator = tf.data.Iterator.from_structure(train_data[2].output_types, train_data[2].output_shapes)\n",
    "#X_tensor, Y_tensor = iterator.get_next()\n",
    "\n",
    "#training_init_op = iterator.make_initializer(train_data[2])\n",
    "#validation_init_op = iterator.make_initializer(val_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      "Tensor(\"X:0\", shape=(?, 16, 16, 16, 1), dtype=float32)\n",
      "Tensor(\"generator/encoder_1/conv3d/BiasAdd:0\", shape=(?, 8, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"generator/encoder_2/batch_normalization_v1/batchnorm/add_1:0\", shape=(?, 4, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator/encoder_3/batch_normalization_v1_1/batchnorm/add_1:0\", shape=(?, 2, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"generator/encoder_4/batch_normalization_v1_2/batchnorm/add_1:0\", shape=(?, 1, 1, 1, 512), dtype=float32)\n",
      "Tensor(\"generator/decoder_4/batch_normalization_v1_3/batchnorm/add_1:0\", shape=(?, 2, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"generator/decoder_3/batch_normalization_v1_4/batchnorm/add_1:0\", shape=(?, 4, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"generator/decoder_2/batch_normalization_v1_5/batchnorm/add_1:0\", shape=(?, 8, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"generator/decoder_1/conv3d_transpose/Reshape_1:0\", shape=(?, 16, 16, 16, 1), dtype=float32)\n",
      "\n",
      "Discriminator\n",
      "Tensor(\"real_discriminator/discriminator/concat:0\", shape=(?, 16, 16, 16, 2), dtype=float32)\n",
      "Tensor(\"real_discriminator/discriminator/layer_1/lrelu/add:0\", shape=(?, 8, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"real_discriminator/discriminator/layer_2/lrelu/add:0\", shape=(?, 4, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"real_discriminator/discriminator/layer_3/lrelu/add:0\", shape=(?, 3, 3, 3, 256), dtype=float32)\n",
      "Tensor(\"real_discriminator/discriminator/layer_4/Sigmoid:0\", shape=(?, 2, 2, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_tensor = tf.placeholder(tf.float32, shape=[None, input_shape[0], input_shape[1], input_shape[2], input_shape[3]], name='X')\n",
    "Y_tensor = tf.placeholder(tf.float32, shape=[None, input_shape[0], input_shape[1], input_shape[2], input_shape[3]], name='Y')\n",
    "\n",
    "with tf.variable_scope(\"generator\"):\n",
    "    Y_generated = Pix2Pix.getGenerator(X_tensor)\n",
    "\n",
    "with tf.name_scope(\"real_discriminator\"):\n",
    "    with tf.variable_scope(\"discriminator\"):\n",
    "        D_logits_real = Pix2Pix.getDiscriminator(X_tensor, Y_tensor)\n",
    "        \n",
    "with tf.name_scope(\"fake_discriminator\"):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=True):\n",
    "        D_logits_fake = Pix2Pix.getDiscriminator(X_tensor, Y_generated)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.abs(Y_generated - Y_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tf.reset_default_graph()\\n\\nX_tensor = tf.placeholder(tf.float32, shape=[None, X.shape[1], X.shape[2], X.shape[3], X.shape[4]], name='X')\\nY_tensor = tf.placeholder(tf.float32, shape=[None, Y.shape[1], Y.shape[2], Y.shape[3], Y.shape[4]], name='Y')\\n\\n# Generator\\nY_generated = UNET.getNetwork(X_tensor)\\nprint(Y_generated)\\n\\n# Discriminator\\nD_logits_real = network.getDiscriminator(tf.concat([X_tensor, Y_tensor], -1))\\nD_logits_fake = network.getDiscriminator(tf.concat([X_tensor, Y_generated], -1), reuse=True)\\nprint(D_logits_real)\\nprint(D_logits_fake)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tf.reset_default_graph()\n",
    "\n",
    "X_tensor = tf.placeholder(tf.float32, shape=[None, X.shape[1], X.shape[2], X.shape[3], X.shape[4]], name='X')\n",
    "Y_tensor = tf.placeholder(tf.float32, shape=[None, Y.shape[1], Y.shape[2], Y.shape[3], Y.shape[4]], name='Y')\n",
    "\n",
    "# Generator\n",
    "Y_generated = UNET.getNetwork(X_tensor)\n",
    "print(Y_generated)\n",
    "\n",
    "# Discriminator\n",
    "D_logits_real = network.getDiscriminator(tf.concat([X_tensor, Y_tensor], -1))\n",
    "D_logits_fake = network.getDiscriminator(tf.concat([X_tensor, Y_generated], -1), reuse=True)\n",
    "print(D_logits_real)\n",
    "print(D_logits_fake)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "batch_size = 1\n",
    "min_val = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12\n",
    "\n",
    "def discriminatorLoss(D_real, D_fake):\n",
    "   \n",
    "    discrim_loss = tf.reduce_mean(-(tf.log(D_real + EPS) + tf.log(1 - D_fake + EPS)))\n",
    "    \n",
    "    return discrim_loss\n",
    "\n",
    "def generatorLoss(D_fake, G_output, target, weight=100.0):\n",
    "    gen_loss_GAN = tf.reduce_mean(-tf.log(D_fake + EPS))\n",
    "    gen_loss_L1 = tf.reduce_mean(tf.abs(target -  G_output))\n",
    "    gen_loss = gen_loss_GAN * 1.0 + gen_loss_L1 * weight\n",
    "\n",
    "    return gen_loss, gen_loss_GAN, gen_loss_L1\n",
    "\n",
    "# Losses\n",
    "D_loss = discriminatorLoss(D_logits_real, D_logits_fake)\n",
    "G_loss, G_gan, G_L1 = generatorLoss(D_logits_fake, Y_generated, Y_tensor)\n",
    "\n",
    "# Optimizers\n",
    "'''D_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')\n",
    "D_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(D_loss, var_list=D_var)\n",
    "\n",
    "G_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\n",
    "G_optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss, var_list=G_var)'''\n",
    "\n",
    "with tf.name_scope('optimize'):\n",
    "    discrim_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n",
    "    discrim_optim = tf.train.AdamOptimizer(lr, 0.5)\n",
    "    discrim_grads_and_vars = discrim_optim.compute_gradients(D_loss, var_list=discrim_tvars)\n",
    "    discrim_train = discrim_optim.apply_gradients(discrim_grads_and_vars)\n",
    "\n",
    "    with tf.control_dependencies([discrim_train]):\n",
    "        gen_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n",
    "        gen_optim = tf.train.AdamOptimizer(lr, 0.5)\n",
    "        gen_grads_and_vars = gen_optim.compute_gradients(G_loss, var_list=gen_tvars)\n",
    "        gen_train = gen_optim.apply_gradients(gen_grads_and_vars)\n",
    "\n",
    "train_op = gen_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b6366b1e8d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a list of summaries\n",
    "tf.summary.scalar(\"D_loss\", D_loss)\n",
    "tf.summary.scalar(\"G_L1\", G_L1)\n",
    "tf.summary.scalar(\"G_gan\", G_gan)\n",
    "\n",
    "tf.summary.image('input', X_tensor[\"x\"][:, :, :, 8], max_outputs=1)\n",
    "tf.summary.image('output', Y_generated[:, :, :, 8], max_outputs=1)\n",
    "tf.summary.image('ground_truth', Y_tensor[:, :, :, 8], max_outputs=1)\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "logs_path = '../checkpoints'\n",
    "# tensorboard --logdir=.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    total_G_loss, total_D_loss = [], [] \n",
    "    i = 0\n",
    "    for _ in range(2500):\n",
    "        sess.run(training_init_op)\n",
    "        while True:\n",
    "            try:\n",
    "                _, summary = sess.run([train_op, merged_summary_op])\n",
    "                summary_writer.add_summary(summary, i)\n",
    "                i += 1\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break  \n",
    "\n",
    "        '''sess.run(validation_init_op)\n",
    "        while True:\n",
    "            try:\n",
    "                acc = sess.run(accuracy)\n",
    "                D_loss_val = np.mean(np.array(total_D_loss))\n",
    "                G_loss_val = np.mean(np.array(total_G_loss))                \n",
    "                \n",
    "                if acc < min_val:\n",
    "                    min_val = acc\n",
    "                    save_path = saver.save(sess, \"../checkpoints/model.ckpt\")\n",
    "                    print(\"SAVED \" + str(D_loss_val) + \" \" + str(G_loss_val) + \" \" + str(min_val))\n",
    "                else:\n",
    "                    print(str(D_loss_val) + \" \" + str(G_loss_val) + \" \" + str(acc))\n",
    "                total_G_loss, total_D_loss = [], []\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED 1.2140636 0.71795607 0.11446164\n",
      "SAVED 0.6377224 1.1591829 0.11142416\n",
      "SAVED 0.083343044 3.0479674 0.09904699\n",
      "SAVED 7.161979 0.0021000835 0.07922016\n",
      "SAVED 1.9013597 0.5479966 0.0636034\n",
      "SAVED 1.3167478 0.64377326 0.053653352\n",
      "1.1992065 1.3468575 0.06675715\n",
      "SAVED 1.2771196 1.5743518 0.039716803\n",
      "SAVED 1.3976945 0.5848418 0.03758063\n",
      "SAVED 1.4949958 0.55569 0.036703456\n",
      "SAVED 1.4916941 0.52330196 0.031400643\n",
      "SAVED 1.4615399 0.5632348 0.02924775\n",
      "1.5452657 0.49866873 0.03332451\n",
      "SAVED 1.5287694 0.48324335 0.025599211\n",
      "SAVED 1.4524856 0.56540453 0.024826296\n",
      "1.6053352 0.45351803 0.026701389\n",
      "SAVED 1.5690409 0.4709841 0.022635177\n",
      "1.5352315 0.5090013 0.023055699\n",
      "SAVED 1.5847158 0.47281525 0.02134616\n",
      "SAVED 1.513006 0.53926504 0.019244526\n",
      "1.5014393 0.5671524 0.024472747\n",
      "SAVED 1.6027713 0.4799173 0.018346619\n",
      "SAVED 1.4435191 0.6266315 0.017799791\n",
      "1.5739243 0.52684104 0.020009182\n",
      "SAVED 1.5753345 0.54816425 0.016950518\n",
      "1.459739 0.6097373 0.017909542\n",
      "SAVED 1.5983981 0.495414 0.014941087\n",
      "SAVED 1.3617852 0.54813194 0.013506594\n",
      "1.4924905 0.47356245 0.019917607\n",
      "1.5335977 0.44345808 0.016172849\n",
      "1.5395247 0.4785673 0.015629387\n",
      "1.4744407 0.48775437 0.016024861\n",
      "1.5126483 0.4496317 0.014747219\n",
      "1.4526279 0.51736224 0.017170455\n",
      "1.473306 0.558249 0.014195466\n",
      "1.4554017 0.6520281 0.01372295\n",
      "SAVED 1.5344423 0.67346305 0.01174257\n",
      "SAVED 1.3934569 0.90094477 0.0117198825\n",
      "1.53533 0.51075095 0.012334876\n",
      "1.315917 0.81453073 0.014596505\n",
      "1.4245193 0.54387337 0.012416329\n",
      "1.3834198 0.50835526 0.01630167\n",
      "1.472794 0.42689735 0.0127164405\n",
      "1.423326 0.5153416 0.012608888\n",
      "1.3654103 0.59006697 0.013098302\n",
      "SAVED 1.3774545 0.5919905 0.011500329\n",
      "1.2847427 0.64622486 0.013206523\n",
      "SAVED 1.3890231 0.5578922 0.010440058\n",
      "1.2384794 0.6642155 0.011559153\n",
      "SAVED 1.3808774 0.5038199 0.010176593\n",
      "1.2862669 0.5876431 0.016618166\n",
      "1.2973104 0.61599946 0.012194632\n",
      "1.2769916 0.72695315 0.012493694\n",
      "1.2966526 0.71975946 0.011692262\n",
      "1.2907169 0.7608974 0.010724187\n",
      "1.2806771 0.8302505 0.010632119\n",
      "SAVED 1.3837928 0.8448108 0.008011321\n",
      "1.1025962 1.1536565 0.01269879\n",
      "1.4817936 0.307017 0.015952954\n",
      "1.0982808 0.6977882 0.015055838\n",
      "1.0569991 0.90195763 0.013429279\n",
      "1.045268 0.92609924 0.013593433\n",
      "1.0293685 0.81637645 0.012611471\n",
      "1.0449862 0.67900825 0.012611529\n",
      "0.9430674 0.93673044 0.013359165\n",
      "1.2663596 0.40683752 0.011291007\n",
      "1.1712649 1.6209252 0.012002731\n",
      "1.0331407 1.1896548 0.0118106855\n",
      "0.9644189 1.0255828 0.011731025\n",
      "0.98774457 0.7021188 0.011245364\n",
      "0.9569351 1.4250348 0.014058942\n",
      "SAVED 1.7102971 0.22054873 0.0076731304\n",
      "SAVED 1.0693929 0.6162743 0.0072866594\n",
      "0.9104834 0.90875137 0.016917113\n",
      "0.93073225 0.7945422 0.012442296\n",
      "0.8669039 1.3083141 0.008349152\n",
      "1.9295325 0.16525608 0.015784226\n",
      "0.88974607 0.8630074 0.012632385\n",
      "0.8275841 1.004181 0.011326123\n",
      "0.90444905 0.6895537 0.012645814\n",
      "1.6861718 2.9182618 0.013634558\n",
      "0.8803538 1.0203419 0.009407267\n",
      "0.84367347 0.9374126 0.011502294\n",
      "0.8454514 0.8096024 0.0112063605\n",
      "0.74510574 1.1766201 0.011470602\n",
      "1.0606549 0.49075216 0.009782329\n",
      "1.3178632 2.3621678 0.008498572\n",
      "0.85824853 1.3903276 0.0109642055\n",
      "0.77988535 0.9927748 0.008136058\n",
      "0.7169117 1.0988634 0.012731081\n",
      "0.707693 1.6619332 0.008729378\n",
      "2.521513 0.08564169 0.010942534\n",
      "0.8535088 0.7028474 0.009368239\n",
      "0.6788131 1.139915 0.012667317\n",
      "0.68462443 1.0209051 0.012729254\n",
      "0.72306585 1.9437851 0.012185631\n",
      "1.8190458 0.18401104 0.008135909\n",
      "0.64929414 1.1789916 0.015964743\n",
      "0.6349849 1.2821732 0.010832101\n",
      "0.5960948 1.1001306 0.007795182\n",
      "0.8310851 2.5727217 0.018614803\n",
      "SAVED 1.0482212 0.47953454 0.004776526\n",
      "0.76075613 0.7960176 0.01106193\n",
      "0.5819291 1.4353842 0.00618463\n",
      "0.5598719 1.2275591 0.01612512\n",
      "0.56235445 1.8354439 0.010654718\n",
      "1.9819341 0.15367773 0.005404408\n",
      "0.76557946 2.2061727 0.014555812\n",
      "0.5881876 1.6455842 0.007307009\n",
      "0.5553272 1.1220899 0.008997288\n",
      "0.47233576 1.8225298 0.0098087555\n",
      "1.1465572 0.39620873 0.0105797555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-39b63761ead5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             _, G_loss_val, D_loss_val = sess.run([train_op, G_gan, D_loss], feed_dict={X_tensor: X[j:j+batch_size],\n\u001b[0;32m---> 20\u001b[0;31m                                                           Y_tensor: Y[j:j+batch_size]})\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtotal_G_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_loss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtotal_D_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_loss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for n in range(3000):\n",
    "        \n",
    "        total_G_loss, total_D_loss = [], []\n",
    "        for j in range(0, len(X), batch_size):\n",
    "        \n",
    "            # Optimize discriminator\n",
    "            _, D_loss_val = sess.run([discrim_train, D_loss], feed_dict={X_tensor: X[j:j+batch_size],\n",
    "                                                                         Y_tensor: Y[j:j+batch_size]})\n",
    "            # Optimizer generator\n",
    "            _, G_loss_val = sess.run([gen_train, G_gan], feed_dict={X_tensor: X[j:j+batch_size],\n",
    "                                                                    Y_tensor: Y[j:j+batch_size]})\n",
    "            \n",
    "\n",
    "            _, G_loss_val, D_loss_val = sess.run([train_op, G_gan, D_loss], feed_dict={X_tensor: X[j:j+batch_size],\n",
    "                                                          Y_tensor: Y[j:j+batch_size]})\n",
    "            total_G_loss.append(G_loss_val)\n",
    "            total_D_loss.append(D_loss_val)\n",
    "\n",
    "        # Get L1 accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={X_tensor: X, Y_tensor: Y})\n",
    "        D_loss_val = np.mean(np.array(total_D_loss))\n",
    "        G_loss_val = np.mean(np.array(total_G_loss))\n",
    "\n",
    "        if acc < min_val:\n",
    "            min_val = acc\n",
    "            save_path = saver.save(sess, \"../checkpoints/model.ckpt\")\n",
    "            print(\"SAVED \" + str(D_loss_val) + \" \" + str(G_loss_val) + \" \" + str(min_val))\n",
    "        else:\n",
    "            print(str(D_loss_val) + \" \" + str(G_loss_val) + \" \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(training_init_op)\n",
    "    saver.restore(sess, \"../checkpoints/model.ckpt\") \n",
    "\n",
    "    img_gen, loss_val, Y, X = sess.run([Y_generated, accuracy, Y_tensor, X_tensor])\n",
    "    \n",
    "    print(loss_val)\n",
    "    print(np.mean(np.abs(img_gen - Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_gen[0,12,5,:,0])\n",
    "print(Y[0,12,5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_ind = 0\n",
    "z = 8\n",
    "\n",
    "data = np.squeeze(img_gen[img_ind,:,:,z], axis=2)\n",
    "print(data.shape)\n",
    "print(X[\"x\"].shape)\n",
    "\n",
    "plt.imshow(data, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.squeeze(X[\"x\"][img_ind,:,:,z], axis=2), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.squeeze(Y[img_ind,:,:,z], axis=2), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
